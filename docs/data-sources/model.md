---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "litellm_model Data Source - terraform-provider-litellm"
subcategory: ""
description: |-
  This data source allow you to fetch data from an existing model in your litellm instance.
  	For a config model be careful the `model_info_id` is an UUID it's not the name like `azure/gpt-4o`.
---

# litellm_model (Data Source)

This data source allow you to fetch data from an existing model in your litellm instance.
		
		For a config model be careful the `model_info_id` is an UUID it's not the name like `azure/gpt-4o`.

## Example Usage

```terraform
data "litellm_model" "my_model" {
    model_info_id = "123e4567-e89b-12d3-a456-426614174000"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `model_info_id` (String) This attribute is the model identifier.

### Optional

- `litellm_params_api_base` (String) Base API Endpoint to use the model
- `litellm_params_api_key` (String) Api key to use to authenticate against the api base
- `litellm_params_api_version` (String) Api version to use when calling the api base
- `litellm_params_aws_access_key_id` (String) AWS Key id, useful for some models
- `litellm_params_aws_region_name` (String) AWS Region where the LLM Model is deployed. Useful for some models.
- `litellm_params_aws_secret_key_id` (String) AWS Key secret, useful for some models
- `litellm_params_configurable_clientside_auth_params` (List of String) Which params are allowed to modify an litellm user.
- `litellm_params_custom_llm_provider` (String) To specify a custom provider for an LLM Model, so LITELLM know the provider.
- `litellm_params_input_cost_per_second` (Number) Input cost per second.
- `litellm_params_input_cost_per_token` (Number) Input cost per token. How much cost a single input token not per 1k tokens or 1M tokens.
- `litellm_params_max_file_size_mb` (Number) Max file size allowed to upload
- `litellm_params_max_retries` (Number) Maximum number of retries before returning an error
- `litellm_params_model` (String) To specify which model to use in the api base endpoint
- `litellm_params_organization` (String) Organization name parameter can be useful for some models
- `litellm_params_output_cost_per_second` (Number) Output cost per second.
- `litellm_params_output_cost_per_token` (Number) Output cost per token. How much cost a single output token not per 1k tokens or 1M tokens.
- `litellm_params_region_name` (String) Region name where the llm is located can be useful for some models
- `litellm_params_rpm` (Number) Max RPM for the model
- `litellm_params_stream_timeout` (Number) When receiving no response form the llm model, time after which timeout is called
- `litellm_params_timeout` (Number) When receiving no response from the llm model, time after which timeout is called
- `litellm_params_tpm` (Number) Max TPM for the model
- `litellm_params_vertex_credentials` (String) GCP credentials to use the vertex LLM Model. Useful for some models
- `litellm_params_vertex_location` (String) GCP Location where the vertex service is deployed. Useful for some models
- `litellm_params_vertex_project` (String) GCP Project ID (not number) where the vertex service is deployed. Useful for some models
- `litellm_params_watsonx_region_name` (String) Watsonx region name
- `model_info_base_model` (String) From which model is derived this model
- `model_info_created_at` (String) When the model has been created
- `model_info_created_by` (String) Who created the model
- `model_info_db_model` (Boolean) Set to true if the is created through terraform-provider-litellm or through the API. If set to false it will be considered like a config model.
- `model_info_tier` (String) Model tier, can be free, enterprise, ...
- `model_info_updated_at` (String) The last time when the model has been updated
- `model_info_updated_by` (String) Who has made the last update to the model
- `model_name` (String) Name of the model to be managed.

### Read-Only

- `id` (String) The ID of this resource.
